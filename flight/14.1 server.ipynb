{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server.py\n",
    "import pyarrow as pa\n",
    "import pyarrow.flight\n",
    "import pyarrow.parquet\n",
    "import pathlib\n",
    "\n",
    "class FlightServer(pa.flight.FlightServerBase):\n",
    "\n",
    "    def __init__(self, location=\"grpc://0.0.0.0:8816\", repo=\"./datasets\"):\n",
    "        super().__init__(location)\n",
    "        self._location = location\n",
    "        self._repo = pathlib.Path(repo)\n",
    "\n",
    "    def _make_flight_info(self, dataset):\n",
    "        dataset_path = self._repo / dataset\n",
    "        metadata = pa.parquet.read_metadata(dataset_path)\n",
    "        descriptor = pa.flight.FlightDescriptor.for_path(dataset.encode())\n",
    "        endpoints = [pa.flight.FlightEndpoint(dataset, [self._location])]\n",
    "        return pa.flight.FlightInfo(\n",
    "            pa.parquet.read_schema(dataset_path),\n",
    "            descriptor,\n",
    "            endpoints,\n",
    "            metadata.num_rows,\n",
    "            metadata.serialized_size\n",
    "        )\n",
    "\n",
    "    def list_flights(self, context, criteria):\n",
    "        for dataset in self._repo.iterdir():\n",
    "            yield self._make_flight_info(dataset.name)\n",
    "\n",
    "    def get_flight_info(self, context, descriptor):\n",
    "        return self._make_flight_info(descriptor.path[0].decode())\n",
    "\n",
    "    def do_put(self, context, descriptor, reader, writer):\n",
    "        dataset = descriptor.path[0].decode()\n",
    "        dataset_path = self._repo / dataset\n",
    "        data_table = reader.read_all()\n",
    "        pa.parquet.write_table(data_table, dataset_path)\n",
    "\n",
    "    def do_get(self, context, ticket):\n",
    "        dataset = ticket.ticket.decode()\n",
    "        dataset_path = self._repo / dataset\n",
    "        return pa.flight.RecordBatchStream(pa.parquet.read_table(dataset_path))\n",
    "\n",
    "    def list_actions(self, context):\n",
    "        return [(\"drop_dataset\", \"Delete a dataset.\")]\n",
    "\n",
    "    def do_action(self, context, action):\n",
    "        if action.type == \"drop_dataset\":\n",
    "            self._drop_dataset(action.body.to_pybytes().decode())\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _drop_dataset(self, dataset):\n",
    "        (self._repo / dataset).unlink()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    server = FlightServer()\n",
    "    server._repo.mkdir(exist_ok=True)\n",
    "    server.serve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81519372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
